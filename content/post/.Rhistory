library(tidyverse)
theme_set(theme_minimal())
# Chunk 3
polls <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-14/polls.csv')
polls
# Chunk 4
sorted <- polls %>%
distinct(title, .keep_all = TRUE) %>%
mutate(bucket = case_when(year < 2000 ~ "Old School",
TRUE ~ "Modern")) %>%
select(-contains("critic"), -rank)
sorted
# Chunk 5
sorted %>%
distinct(title, .keep_all = TRUE) %>%
count(bucket, gender)
# Chunk 6
library(genius)
#lyrics <- sorted %>% add_genius(artist, title, type = "lyrics")
lyrics <- read_csv("https://raw.githubusercontent.com/DesmondChoy/DataSets/master/lyrics.csv")
# Chunk 7
lyrics %>%
distinct(title, .keep_all = TRUE)
lyrics <- lyrics %>%
na.omit()
# Chunk 8
library(tidytext)
library(textdata)
tidy_lyrics <- lyrics %>%
unnest_tokens(word, lyric) %>%
anti_join(stop_words, by = "word") %>%
inner_join(get_sentiments("nrc")) %>%
select(-track_title) #repeated column
tidy_lyrics %>%
select(word, sentiment, line, title, artist, bucket) %>%
sample_n(10)
# Chunk 9
tidy_lyrics %>%
count(word, sort = TRUE)
# Chunk 10
#Calculating total words per song
totals <- tidy_lyrics %>%
count(title) %>%
rename(total_words = n)
#Joining it back to the original dataframe
lyrics_count <- tidy_lyrics %>%
left_join(totals, by = "title")
# Chunk 11
lyrics_count %>%
filter(sentiment == "negative") %>%
count(title, sentiment, total_words) %>%
ungroup() %>%
mutate(percent = n/total_words) %>%
arrange(desc(percent))
# Chunk 12
lyrics_count %>%
filter(
sentiment %in% c("positive", "negative", "joy", "fear", "anger", "trust"),
total_words > 10
) %>%
count(title, sentiment, total_words, artist) %>%
mutate(percent = n / total_words,
title = paste(artist, title, sep = " - ")) %>%
arrange(desc(percent)) %>%
group_by(sentiment) %>%
slice(1:10) %>%
ggplot(aes(reorder_within(title, percent, sentiment), percent, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(
. ~ fct_relevel(sentiment, "positive", "negative", "joy", "fear", "trust"),
scales = "free",
ncol = 2
) +
coord_flip() +
scale_x_reordered() +
scale_y_continuous(labels = scales::label_percent(accuracy = 1)) +
labs(
x = "",
y = "Percentage of song's lyrics in each category",
title = "Tidy Text Mining: Using Sentiment Analysis to Group Hip-Hop Songs across Emotions",
subtitle = "Selected Hip-Hop Songs from BBC Poll; Categories from NRC Emotion Lexicon; Lyrics from Genius package"
) +
theme(
plot.title = element_text(face = "bold", size = 20),
plot.title.position = "plot",
plot.subtitle = element_text(size = 15),
strip.background = element_blank(),
strip.text = element_text(face = "bold", size = 15)
)
# Chunk 13
song_sentiment <- tidy_lyrics %>%
count(title, artist, index = line %/% 4, sentiment) %>%
pivot_wider(
names_from = sentiment,
values_from = n,
values_fill = list(n = 0)) %>%
mutate(sentiment = positive - negative)
set.seed(2000)
sample <- song_sentiment %>%
distinct(title) %>%
sample_n(10) %>%
pull(title)
song_sentiment %>%
filter(title %in% sample) %>%
mutate(title = paste(artist, title, sep = " - ")) %>%
ggplot(aes(index, sentiment, fill = title)) +
geom_col(show.legend = FALSE) +
facet_wrap(. ~ title, ncol = 2, scales = c("free")) +
labs(
x = "Duration",
y = "Sentiment Score",
title = "Visualising Sentiment Scores for 10 randomly selected hip-hop songs",
subtitle = "Positive scores indicate positive sentiment, and vice versa."
) +
theme(
plot.title = element_text(face = "bold", size = 20),
plot.title.position = "plot",
plot.subtitle = element_text(size = 15),
strip.background = element_blank(),
strip.text = element_text(face = "bold", size = 15)
)
# Chunk 14
library(tidymodels)
set.seed(2000)
hiphop_split <- initial_split(lyrics, strata = bucket)
hiphop_split
hiphop_train <- training(hiphop_split)
hiphop_test <- testing(hiphop_split)
# Chunk 15
set.seed(2000)
folds <- vfold_cv(hiphop_train, v = 10)
folds
# Chunk 16
lr_model <- logistic_reg(penalty = tune(),
mixture = 1) %>%
set_engine("glmnet")
# Chunk 17
library(textrecipes)
hiphop_rec <- hiphop_train %>%
recipe(bucket ~ lyric + gender) %>%
step_tokenize(lyric) %>%
step_stopwords(lyric) %>%
step_tokenfilter(lyric, max_tokens = 2000) %>%
step_tfidf(lyric) %>%
step_normalize(all_predictors(),-gender) %>%
step_dummy(all_nominal(), -all_outcomes())
prep(hiphop_rec)
# Chunk 18
lr_wflow <- workflow() %>%
add_model(lr_model) %>%
add_recipe(hiphop_rec)
lr_wflow
# Chunk 19
grid <- grid_regular(penalty(), levels = 40)
doParallel::registerDoParallel()
set.seed(2000)
lr_grid <- tune_grid(
lr_wflow,
resamples = folds,
grid = grid,
metrics = metric_set(roc_auc, npv, ppv, mn_log_loss))
# Chunk 1: setup
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE)
# Chunk 2
library(tidyverse)
theme_set(theme_minimal())
# Chunk 3
polls <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-14/polls.csv')
polls
# Chunk 4
sorted <- polls %>%
distinct(title, .keep_all = TRUE) %>%
mutate(bucket = case_when(year < 2000 ~ "Old School",
TRUE ~ "Modern")) %>%
select(-contains("critic"), -rank)
sorted
# Chunk 5
sorted %>%
distinct(title, .keep_all = TRUE) %>%
count(bucket, gender)
# Chunk 6
library(genius)
#lyrics <- sorted %>% add_genius(artist, title, type = "lyrics")
lyrics <- read_csv("https://raw.githubusercontent.com/DesmondChoy/DataSets/master/lyrics.csv")
# Chunk 7
lyrics %>%
distinct(title, .keep_all = TRUE)
lyrics <- lyrics %>%
na.omit()
# Chunk 8
library(tidytext)
library(textdata)
tidy_lyrics <- lyrics %>%
unnest_tokens(word, lyric) %>%
anti_join(stop_words, by = "word") %>%
inner_join(get_sentiments("nrc")) %>%
select(-track_title) #repeated column
tidy_lyrics %>%
select(word, sentiment, line, title, artist, bucket) %>%
sample_n(10)
# Chunk 9
tidy_lyrics %>%
count(word, sort = TRUE)
# Chunk 10
#Calculating total words per song
totals <- tidy_lyrics %>%
count(title) %>%
rename(total_words = n)
#Joining it back to the original dataframe
lyrics_count <- tidy_lyrics %>%
left_join(totals, by = "title")
# Chunk 11
lyrics_count %>%
filter(sentiment == "negative") %>%
count(title, sentiment, total_words) %>%
ungroup() %>%
mutate(percent = n/total_words) %>%
arrange(desc(percent))
# Chunk 12
lyrics_count %>%
filter(
sentiment %in% c("positive", "negative", "joy", "fear", "anger", "trust"),
total_words > 10
) %>%
count(title, sentiment, total_words, artist) %>%
mutate(percent = n / total_words,
title = paste(artist, title, sep = " - ")) %>%
arrange(desc(percent)) %>%
group_by(sentiment) %>%
slice(1:10) %>%
ggplot(aes(reorder_within(title, percent, sentiment), percent, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(
. ~ fct_relevel(sentiment, "positive", "negative", "joy", "fear", "trust"),
scales = "free",
ncol = 2
) +
coord_flip() +
scale_x_reordered() +
scale_y_continuous(labels = scales::label_percent(accuracy = 1)) +
labs(
x = "",
y = "Percentage of song's lyrics in each category",
title = "Tidy Text Mining: Using Sentiment Analysis to Group Hip-Hop Songs across Emotions",
subtitle = "Selected Hip-Hop Songs from BBC Poll; Categories from NRC Emotion Lexicon; Lyrics from Genius package"
) +
theme(
plot.title = element_text(face = "bold", size = 20),
plot.title.position = "plot",
plot.subtitle = element_text(size = 15),
strip.background = element_blank(),
strip.text = element_text(face = "bold", size = 15)
)
# Chunk 13
song_sentiment <- tidy_lyrics %>%
count(title, artist, index = line %/% 4, sentiment) %>%
pivot_wider(
names_from = sentiment,
values_from = n,
values_fill = list(n = 0)) %>%
mutate(sentiment = positive - negative)
set.seed(2000)
sample <- song_sentiment %>%
distinct(title) %>%
sample_n(10) %>%
pull(title)
song_sentiment %>%
filter(title %in% sample) %>%
mutate(title = paste(artist, title, sep = " - ")) %>%
ggplot(aes(index, sentiment, fill = title)) +
geom_col(show.legend = FALSE) +
facet_wrap(. ~ title, ncol = 2, scales = c("free")) +
labs(
x = "Duration",
y = "Sentiment Score",
title = "Visualising Sentiment Scores for 10 randomly selected hip-hop songs",
subtitle = "Positive scores indicate positive sentiment, and vice versa."
) +
theme(
plot.title = element_text(face = "bold", size = 20),
plot.title.position = "plot",
plot.subtitle = element_text(size = 15),
strip.background = element_blank(),
strip.text = element_text(face = "bold", size = 15)
)
# Chunk 14
library(tidymodels)
set.seed(2000)
hiphop_split <- initial_split(lyrics, strata = bucket)
hiphop_split
hiphop_train <- training(hiphop_split)
hiphop_test <- testing(hiphop_split)
# Chunk 15
set.seed(2000)
folds <- vfold_cv(hiphop_train, v = 10)
folds
# Chunk 16
lr_model <- logistic_reg(penalty = tune(),
mixture = 1) %>%
set_engine("glmnet")
# Chunk 17
library(textrecipes)
hiphop_rec <- hiphop_train %>%
recipe(bucket ~ lyric + gender) %>%
step_tokenize(lyric) %>%
step_stopwords(lyric) %>%
step_tokenfilter(lyric, max_tokens = 2000) %>%
step_tfidf(lyric) %>%
step_normalize(all_predictors(),-gender) %>%
step_dummy(all_nominal(), -all_outcomes())
prep(hiphop_rec)
# Chunk 18
lr_wflow <- workflow() %>%
add_model(lr_model) %>%
add_recipe(hiphop_rec)
lr_wflow
# Chunk 19
grid <- grid_regular(penalty(), levels = 40)
library(doParallel)
cl <- makePSOCKcluster(parallel::detectCores(logical = FALSE))
cl
registerDoParallel(cl)
set.seed(2000)
lr_grid <- tune_grid(
lr_wflow,
resamples = folds,
grid = grid,
metrics = metric_set(roc_auc, npv, ppv, mn_log_loss))
cl <- makePSOCKcluster(parallel::detectCores(logical = FALSE))
registerDoParallel(cl)
foreach::getDoParWorkers()
clusterEvalQ(cl, {library(tidymodels)})
doParallel::registerDoParallel()
set.seed(2000)
lr_grid <- tune_grid(
lr_wflow,
resamples = folds,
grid = grid,
metrics = metric_set(roc_auc, npv, ppv, mn_log_loss))
# Chunk 1: setup
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE)
# Chunk 2
library(tidyverse)
theme_set(theme_minimal())
# Chunk 3
polls <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-14/polls.csv')
polls
# Chunk 4
sorted <- polls %>%
distinct(title, .keep_all = TRUE) %>%
mutate(bucket = case_when(year < 2000 ~ "Old School",
TRUE ~ "Modern")) %>%
select(-contains("critic"), -rank)
sorted
# Chunk 5
sorted %>%
distinct(title, .keep_all = TRUE) %>%
count(bucket, gender)
# Chunk 6
library(genius)
#lyrics <- sorted %>% add_genius(artist, title, type = "lyrics")
lyrics <- read_csv("https://raw.githubusercontent.com/DesmondChoy/DataSets/master/lyrics.csv")
# Chunk 7
lyrics %>%
distinct(title, .keep_all = TRUE)
lyrics <- lyrics %>%
na.omit()
# Chunk 8
library(tidytext)
library(textdata)
tidy_lyrics <- lyrics %>%
unnest_tokens(word, lyric) %>%
anti_join(stop_words, by = "word") %>%
inner_join(get_sentiments("nrc")) %>%
select(-track_title) #repeated column
tidy_lyrics %>%
select(word, sentiment, line, title, artist, bucket) %>%
sample_n(10)
# Chunk 9
tidy_lyrics %>%
count(word, sort = TRUE)
# Chunk 10
#Calculating total words per song
totals <- tidy_lyrics %>%
count(title) %>%
rename(total_words = n)
#Joining it back to the original dataframe
lyrics_count <- tidy_lyrics %>%
left_join(totals, by = "title")
# Chunk 11
lyrics_count %>%
filter(sentiment == "negative") %>%
count(title, sentiment, total_words) %>%
ungroup() %>%
mutate(percent = n/total_words) %>%
arrange(desc(percent))
# Chunk 12
lyrics_count %>%
filter(
sentiment %in% c("positive", "negative", "joy", "fear", "anger", "trust"),
total_words > 10
) %>%
count(title, sentiment, total_words, artist) %>%
mutate(percent = n / total_words,
title = paste(artist, title, sep = " - ")) %>%
arrange(desc(percent)) %>%
group_by(sentiment) %>%
slice(1:10) %>%
ggplot(aes(reorder_within(title, percent, sentiment), percent, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(
. ~ fct_relevel(sentiment, "positive", "negative", "joy", "fear", "trust"),
scales = "free",
ncol = 2
) +
coord_flip() +
scale_x_reordered() +
scale_y_continuous(labels = scales::label_percent(accuracy = 1)) +
labs(
x = "",
y = "Percentage of song's lyrics in each category",
title = "Tidy Text Mining: Using Sentiment Analysis to Group Hip-Hop Songs across Emotions",
subtitle = "Selected Hip-Hop Songs from BBC Poll; Categories from NRC Emotion Lexicon; Lyrics from Genius package"
) +
theme(
plot.title = element_text(face = "bold", size = 20),
plot.title.position = "plot",
plot.subtitle = element_text(size = 15),
strip.background = element_blank(),
strip.text = element_text(face = "bold", size = 15)
)
# Chunk 13
song_sentiment <- tidy_lyrics %>%
count(title, artist, index = line %/% 4, sentiment) %>%
pivot_wider(
names_from = sentiment,
values_from = n,
values_fill = list(n = 0)) %>%
mutate(sentiment = positive - negative)
set.seed(2000)
sample <- song_sentiment %>%
distinct(title) %>%
sample_n(10) %>%
pull(title)
song_sentiment %>%
filter(title %in% sample) %>%
mutate(title = paste(artist, title, sep = " - ")) %>%
ggplot(aes(index, sentiment, fill = title)) +
geom_col(show.legend = FALSE) +
facet_wrap(. ~ title, ncol = 2, scales = c("free")) +
labs(
x = "Duration",
y = "Sentiment Score",
title = "Visualising Sentiment Scores for 10 randomly selected hip-hop songs",
subtitle = "Positive scores indicate positive sentiment, and vice versa."
) +
theme(
plot.title = element_text(face = "bold", size = 20),
plot.title.position = "plot",
plot.subtitle = element_text(size = 15),
strip.background = element_blank(),
strip.text = element_text(face = "bold", size = 15)
)
# Chunk 14
library(tidymodels)
set.seed(2000)
hiphop_split <- initial_split(lyrics, strata = bucket)
hiphop_split
hiphop_train <- training(hiphop_split)
hiphop_test <- testing(hiphop_split)
# Chunk 15
set.seed(2000)
folds <- vfold_cv(hiphop_train, v = 10)
folds
# Chunk 16
lr_model <- logistic_reg(penalty = tune(),
mixture = 1) %>%
set_engine("glmnet")
# Chunk 17
library(textrecipes)
hiphop_rec <- hiphop_train %>%
recipe(bucket ~ lyric + gender) %>%
step_tokenize(lyric) %>%
step_stopwords(lyric) %>%
step_tokenfilter(lyric, max_tokens = 2000) %>%
step_tfidf(lyric) %>%
step_normalize(all_predictors(),-gender) %>%
step_dummy(all_nominal(), -all_outcomes())
prep(hiphop_rec)
# Chunk 18
lr_wflow <- workflow() %>%
add_model(lr_model) %>%
add_recipe(hiphop_rec)
lr_wflow
# Chunk 19
grid <- grid_regular(penalty(), levels = 40)
library(doParallel)
cl <- makePSOCKcluster(parallel::detectCores(logical = FALSE))
registerDoParallel(cl)
foreach::getDoParWorkers()
clusterEvalQ(cl, {library(tidymodels)})
doParallel::registerDoParallel()
lr_grid <- tune_grid(
lr_wflow,
resamples = folds,
grid = grid,
metrics = metric_set(roc_auc, npv, ppv, mn_log_loss))
blogdown:::serve_site()
