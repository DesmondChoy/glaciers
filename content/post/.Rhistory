knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
fig.width = 15,
fig.height = 12)
library(readxl) #data importing
library(tidyverse) #data wrangling
library(magrittr) #data wrangling
library(lubridate) #date manipulation
library(hrbrthemes) #ggplot themes
library(ggrepel) #ggplot identification of data points
Sectors <- read_xlsx("https://github.com/DesmondChoy/glaciers/blob/master/content/post/Sectors.xlsx", na = "NA")
?readxl::read_xlsx
Sectors <- read_xlsx("github.com/DesmondChoy/glaciers/blob/master/content/post/Sectors.xlsx", na = "NA")
Sectors <- read_excel("https://github.com/DesmondChoy/glaciers/blob/master/content/post/Sectors.xlsx")
Sectors <- read_xlsx("Sectors", na = "NA")
Sectors <- read_xlsx("Sectors.xlsx", na = "NA")
Sectors <- Sectors[-c(1:3),]
Periods <- read_xlsx("Periods.xlsx", na = "NA")
Periods <- Periods[-c(1:3),]
Energy <- left_join(Sectors, Periods)
Energy <- distinct(Energy, CUSIP, .keep_all = TRUE)
names(Energy) <- tolower(gsub("\\s", "\\.", names(Energy)))
blogdown:::serve_site()
Energy %>%
filter(ticker %in% c("TOPTB", "VLO")) %>%
select(ticker, security, cusip, bclass.level.4.classification.name, bloomberg.composite.rating)
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
fig.width = 15,
fig.height = 12)
library(readxl) #data importing
library(tidyverse) #data wrangling
library(magrittr) #data wrangling
library(lubridate) #date manipulation
library(hrbrthemes) #ggplot themes
library(ggrepel) #ggplot identification of data points
Sectors <- read_xlsx("Sectors.xlsx", na = "NA")
Sectors <- Sectors[-c(1:3),]
Periods <- read_xlsx("Periods.xlsx", na = "NA")
Periods <- Periods[-c(1:3),]
Energy <- left_join(Sectors, Periods)
Energy <- distinct(Energy, CUSIP, .keep_all = TRUE)
names(Energy) <- tolower(gsub("\\s", "\\.", names(Energy)))
library(skimr)
skim(Energy)
Energy$bloomberg.composite.rating <-
as_factor(Energy$bloomberg.composite.rating) %>%
factor(levels = c("AA+", "AA", "AA-", "A+", "A", "A-", "BBB+", "BBB", "BBB-", "BB+", "NR"))
Energy$ticker <- str_extract(Energy$security, "^\\w+")
Energy$year <- str_extract(Energy$security, "\\d\\d$")
Energy$coupon <- str_extract(Energy$security, "\\s.+\\s")
Energy$maturity <- as.numeric((mdy(str_extract(Energy$security, "\\d+/.+$")) - today())/365)
Energy$`moody's.rating` <- as_factor(Energy$`moody's.rating`)
Energy$`s&p.rating` <- as_factor(Energy$`s&p.rating`)
Energy$crncy <- as_factor(Energy$crncy)
Energy$bclass.level.4.classification.name <-
as_factor(Energy$bclass.level.4.classification.name) %>%
factor(
levels = c(
"Integrated",
"Independent",
"Midstream",
"Refining",
"Oil Field Services",
"Government Owned, No Guarantee"
)
Energy <- Energy %>%
filter(!ticker %in% c("PAA", "BHI", "SLB", "HAL"))
Energy %>%
filter(ticker %in% c("SINOPE", "CNPCCH", "PETMK", "PTTTB", "STOAU", "CNOOC", "TOPTB", "VLO")) %>%
group_by(ticker, bclass.level.4.classification.name) %>%
summarise(n = n()) %>%
arrange(bclass.level.4.classification.name)
Energy %>%
filter(ticker %in% c("TOPTB", "VLO")) %>%
select(ticker, security, cusip, bclass.level.4.classification.name, bloomberg.composite.rating)
Energy %>%
filter(ticker %in% c("TOPTB", "VLO")) %>%
select(ticker, security, cusip, bclass.level.4.classification.name, bloomberg.composite.rating) %>%
knitr::kable()
library(tidyverse)
theme_set(theme_minimal())
This will be my first attempt at machine learning using the `tidymodels` package, with this dataset is taken from [TidyTuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-18/readme.md) - the code used to scrape this data can be found [here](https://r-tastic.co.uk/post/from-messy-to-tidy/).   The study analyses data from the Food and Agriculture Organization of the United Nations (FAO) to determine the quantity of produce supplied for consumption of 11 food types for all countries researched. Using CO2 emissions data, the carbon footprint per capita is then calculated for each food type.
# Chunk 1: Setup
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE)
# Chunk 2: Libraries
library(tidyverse)
theme_set(theme_minimal())
# Chunk 3
food_consumption <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-18/food_consumption.csv")
food_consumption
# Chunk 4
library(skimr)
skim(food_consumption)
food_consumption %>%
count(food_category)
# Chunk 5
food_consumption %>%
group_by(food_category) %>%
summarize(avg.co2 = sum(co2_emmission)/n()) %>%
ggplot(aes(fct_reorder(food_category, avg.co2), avg.co2, fill = food_category)) +
geom_col(show.legend = F) +
coord_flip() +
labs(
x = "Food Categories",
y = "Average CO2 Emissions"
)
# Chunk 6
library(ggrepel) #ggplot identification of data points
food_consumption %>%
group_by(food_category) %>%
ggplot(aes(
fct_reorder(food_category, co2_emmission),
co2_emmission,
fill = food_category
)) +
geom_boxplot(show.legend = F) +
geom_text_repel(
data = . %>%
filter(food_category == "Beef") %>%
mutate(percentile = co2_emmission >= quantile(co2_emmission, 0.95, na.rm = T)) %>%
filter(percentile == 1),
aes(label = country)
) +
coord_flip() +
labs(
x = "Food Categories",
y = "Average CO2 Emissions"
)
# Chunk 7
food_consumption %>%
filter(food_category == "Beef") %>%
arrange(desc(consumption)) %>%
top_n(20) %>%
ggplot(aes(fct_reorder(country, consumption), consumption, fill = country)) +
geom_col(show.legend = F) +
coord_flip() +
labs(
x = "Country",
y = "Beef Consumption"
)
# Chunk 8
library(countrycode)
library(janitor)
food <- food_consumption %>%
select(-consumption) %>%
pivot_wider(names_from = food_category,
values_from = co2_emmission) %>%
clean_names() %>%
mutate(continent = countrycode(country,
origin = "country.name",
destination = "continent")) %>%
mutate(americas = case_when(continent == "Americas" ~ "Americas",
TRUE ~ "Other")) %>%
select(-country,-continent) %>%
mutate_if(is.character, as_factor)
food %>%
select(americas, everything())
# Chunk 9
library(GGally)
food %>%
ggscatmat(columns = 1:11, color = "americas", alpha = 0.7)
# Chunk 10
library(tidymodels)
set.seed(2020)
food_split <- initial_split(food, strata = americas)
food_split
food_train <- training(food_split)
food_test <- testing(food_split)
food_train
food_rec <- recipe(americas ~ ., data = food_train) %>%
step_corr(all_numeric()) %>%
step_normalize(all_numeric()) %>%
prep()
food_rec
log_spec <- logistic_reg(mode = "classification") %>%
set_engine("glm")
rf_spec <- rand_forest(mode = "classification") %>%
set_engine("ranger")
log_fit <- log_spec %>%
fit(americas ~ .,
data = juice(food_rec))
log_fit
rf_fit <- rf_spec %>%
fit(americas ~ .,
data = juice(food_rec))
rf_fit
results_train <- log_fit %>%
predict(new_data = food_train) %>%
mutate(truth = food_train$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "log") %>%
bind_rows(
rf_fit %>%
predict(new_data = food_train) %>%
mutate(truth = food_train$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "rf")
)
results_test <- log_fit %>%
predict(new_data = food_test) %>%
mutate(truth = food_test$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "log") %>%
bind_rows(
rf_fit %>%
predict(new_data = food_test) %>%
mutate(truth = food_test$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "rf")
)
library(patchwork) #to combine ggplots
p1 <- results_train %>%
filter(.metric %in% c("accuracy", "precision", "recall", "f_meas")) %>%
ggplot(aes(.metric, .estimate, fill = model)) +
geom_col(position = "dodge2") +
geom_text(aes(label = round(.estimate, 2)),
position = position_dodge(width = 0.9), vjust = -0.5) +
labs(
x = "Performance Metrics (Training Data)",
y = "Score"
)
p2 <- results_test %>%
filter(.metric %in% c("accuracy", "precision", "recall", "f_meas")) %>%
ggplot(aes(.metric, .estimate, fill = model)) +
geom_col(position = "dodge2") +
geom_text(aes(label = round(.estimate, 2)),
position = position_dodge(width = 0.9), vjust = -0.5) +
labs(
x = "Performance Metrics (Test Data)",
y = "Score"
)
p1 + p2 + plot_layout(guides = "collect") & theme(legend.position = 'bottom')
food_rec <- recipe(americas ~ ., data = food_train) %>%
step_corr(all_numeric()) %>%
prep()
food_rec
log_fit <- log_spec %>%
fit(americas ~ .,
data = juice(food_rec))
log_fit
rf_fit <- rf_spec %>%
fit(americas ~ .,
data = juice(food_rec))
rf_fit
results_train <- log_fit %>%
predict(new_data = food_train) %>%
mutate(truth = food_train$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "log") %>%
bind_rows(
rf_fit %>%
predict(new_data = food_train) %>%
mutate(truth = food_train$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "rf")
)
results_test <- log_fit %>%
predict(new_data = food_test) %>%
mutate(truth = food_test$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "log") %>%
bind_rows(
rf_fit %>%
predict(new_data = food_test) %>%
mutate(truth = food_test$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "rf")
)
library(patchwork) #to combine ggplots
p1 <- results_train %>%
filter(.metric %in% c("accuracy", "precision", "recall", "f_meas")) %>%
ggplot(aes(.metric, .estimate, fill = model)) +
geom_col(position = "dodge2") +
geom_text(aes(label = round(.estimate, 2)),
position = position_dodge(width = 0.9), vjust = -0.5) +
labs(
x = "Performance Metrics (Training Data)",
y = "Score"
)
p2 <- results_test %>%
filter(.metric %in% c("accuracy", "precision", "recall", "f_meas")) %>%
ggplot(aes(.metric, .estimate, fill = model)) +
geom_col(position = "dodge2") +
geom_text(aes(label = round(.estimate, 2)),
position = position_dodge(width = 0.9), vjust = -0.5) +
labs(
x = "Performance Metrics (Test Data)",
y = "Score"
)
p1 + p2 + plot_layout(guides = "collect") & theme(legend.position = 'bottom')
# Chunk 1: Setup
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE)
# Chunk 2: Libraries
library(tidyverse)
theme_set(theme_minimal())
# Chunk 3
food_consumption <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-18/food_consumption.csv")
food_consumption
# Chunk 4
library(skimr)
skim(food_consumption)
food_consumption %>%
count(food_category)
# Chunk 5
food_consumption %>%
group_by(food_category) %>%
summarize(avg.co2 = sum(co2_emmission)/n()) %>%
ggplot(aes(fct_reorder(food_category, avg.co2), avg.co2, fill = food_category)) +
geom_col(show.legend = F) +
coord_flip() +
labs(
x = "Food Categories",
y = "Average CO2 Emissions"
)
# Chunk 6
library(ggrepel) #ggplot identification of data points
food_consumption %>%
group_by(food_category) %>%
ggplot(aes(
fct_reorder(food_category, co2_emmission),
co2_emmission,
fill = food_category
)) +
geom_boxplot(show.legend = F) +
geom_text_repel(
data = . %>%
filter(food_category == "Beef") %>%
mutate(percentile = co2_emmission >= quantile(co2_emmission, 0.95, na.rm = T)) %>%
filter(percentile == 1),
aes(label = country)
) +
coord_flip() +
labs(
x = "Food Categories",
y = "Average CO2 Emissions"
)
# Chunk 7
food_consumption %>%
filter(food_category == "Beef") %>%
arrange(desc(consumption)) %>%
top_n(20) %>%
ggplot(aes(fct_reorder(country, consumption), consumption, fill = country)) +
geom_col(show.legend = F) +
coord_flip() +
labs(
x = "Country",
y = "Beef Consumption"
)
# Chunk 8
library(countrycode)
library(janitor)
food <- food_consumption %>%
select(-consumption) %>%
pivot_wider(names_from = food_category,
values_from = co2_emmission) %>%
clean_names() %>%
mutate(continent = countrycode(country,
origin = "country.name",
destination = "continent")) %>%
mutate(americas = case_when(continent == "Americas" ~ "Americas",
TRUE ~ "Other")) %>%
select(-country,-continent) %>%
mutate_if(is.character, as_factor)
food %>%
select(americas, everything())
# Chunk 9
library(GGally)
food %>%
ggscatmat(columns = 1:11, color = "americas", alpha = 0.7)
# Chunk 10
library(tidymodels)
set.seed(2020)
food_split <- initial_split(food, strata = americas)
food_split
food_train <- training(food_split)
food_test <- testing(food_split)
# Chunk 11
food_rec <- recipe(americas ~ ., data = food_train) %>%
step_corr(all_numeric()) %>%
prep()
food_rec
# Chunk 12
log_spec <- logistic_reg(mode = "classification") %>%
set_engine("glm")
rf_spec <- rand_forest(mode = "classification") %>%
set_engine("ranger")
# Chunk 13
log_fit <- log_spec %>%
fit(americas ~ .,
data = juice(food_rec))
log_fit
# Chunk 14
rf_fit <- rf_spec %>%
fit(americas ~ .,
data = juice(food_rec))
rf_fit
results_train <- log_fit %>%
predict(new_data = food_train) %>%
mutate(truth = food_train$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "log") %>%
bind_rows(
rf_fit %>%
predict(new_data = food_train) %>%
mutate(truth = food_train$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "rf")
)
results_test <- log_fit %>%
predict(new_data = food_test) %>%
mutate(truth = food_test$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "log") %>%
bind_rows(
rf_fit %>%
predict(new_data = food_test) %>%
mutate(truth = food_test$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "rf")
)
library(patchwork) #to combine ggplots
p1 <- results_train %>%
filter(.metric %in% c("accuracy", "precision", "recall", "f_meas")) %>%
ggplot(aes(.metric, .estimate, fill = model)) +
geom_col(position = "dodge2") +
geom_text(aes(label = round(.estimate, 2)),
position = position_dodge(width = 0.9), vjust = -0.5) +
labs(
x = "Performance Metrics (Training Data)",
y = "Score"
)
p2 <- results_test %>%
filter(.metric %in% c("accuracy", "precision", "recall", "f_meas")) %>%
ggplot(aes(.metric, .estimate, fill = model)) +
geom_col(position = "dodge2") +
geom_text(aes(label = round(.estimate, 2)),
position = position_dodge(width = 0.9), vjust = -0.5) +
labs(
x = "Performance Metrics (Test Data)",
y = "Score"
)
p1 + p2 + plot_layout(guides = "collect") & theme(legend.position = 'bottom')
results_train <- log_fit %>%
predict(new_data = food_train) %>%
mutate(truth = food_train$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "log") %>%
bind_rows(
rf_fit %>%
predict(new_data = food_train) %>%
mutate(truth = food_train$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "rf")
)
results_test <- log_fit %>%
predict(new_data = bake(food_rec, food_test)) %>%
mutate(truth = food_test$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "log") %>%
bind_rows(
rf_fit %>%
predict(new_data = bake(food_rec, food_test)) %>%
mutate(truth = food_test$americas) %>%
conf_mat(truth, .pred_class) %>%
summary() %>%
mutate(model = "rf")
)
library(patchwork) #to combine ggplots
p1 <- results_train %>%
filter(.metric %in% c("accuracy", "precision", "recall", "f_meas")) %>%
ggplot(aes(.metric, .estimate, fill = model)) +
geom_col(position = "dodge2") +
geom_text(aes(label = round(.estimate, 2)),
position = position_dodge(width = 0.9), vjust = -0.5) +
labs(
x = "Performance Metrics (Training Data)",
y = "Score"
)
p2 <- results_test %>%
filter(.metric %in% c("accuracy", "precision", "recall", "f_meas")) %>%
ggplot(aes(.metric, .estimate, fill = model)) +
geom_col(position = "dodge2") +
geom_text(aes(label = round(.estimate, 2)),
position = position_dodge(width = 0.9), vjust = -0.5) +
labs(
x = "Performance Metrics (Test Data)",
y = "Score"
)
p1 + p2 + plot_layout(guides = "collect") & theme(legend.position = 'bottom')
blogdown:::serve_site()
