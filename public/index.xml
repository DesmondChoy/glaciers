<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Desmond Choy&#39;s Blog</title>
    <link>/</link>
    <description>Recent content on Desmond Choy&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 29 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Exploring Share Prices and Sentiment</title>
      <link>/2020/05/exploring-share-prices-and-sentiment/</link>
      <pubDate>Fri, 29 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/05/exploring-share-prices-and-sentiment/</guid>
      <description>Despite these troubling times brought upon us by Covid-19, one interesting investment theme has outperformed the market - “stay-at-home” stocks. These generally consist of companies that would benefit from the lockdown such as big retailers with delivery services, tech companies providing essential software for WFH setups, and video gaming companies that benefit from bored kids and adults. These companies have outperformed the broader indices significantly and, intuitively, sentiment for these companies should be positive, right?</description>
    </item>
    
    <item>
      <title>Hip-Hop Lyrics Be Flowing with Tidy Text Mining</title>
      <link>/2020/05/hip-hop-lyrics-be-flowin-with-tidy-text-mining/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/05/hip-hop-lyrics-be-flowin-with-tidy-text-mining/</guid>
      <description>I’ve been hit with a double dose of NLP inspiration after reading a recent Julia Silge blog post and watching a Datacamp video on Tidy Text Mining which she used to teach. Ergo, this post will set out to do two things: use sentiment analysis to explore hip-hop songs, and subsequently use the tidymodels package on the lyrics to predict which era (Old School versus Modern) the songs came from.</description>
    </item>
    
    <item>
      <title>Being Picky About Free Textbooks From Springer</title>
      <link>/2020/04/being-picky-about-free-textbooks-from-springer/</link>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/04/being-picky-about-free-textbooks-from-springer/</guid>
      <description>You might have heard that Springer Nature, an American German academic publishing company, is giving free access to more than 500 key textbooks across Springer Nature’s eBook subject collections, as their way to support lecturers, teachers and students and grant remote access to essential educational resources during this Covid-19 lockdown period. A repository of the books can be found here.
To my delight, I stumbled across the springerQuarantineBooksR package made by Renan Xavier Cortes in a blog post.</description>
    </item>
    
    <item>
      <title>Food Consumption and CO2 Emissions</title>
      <link>/2020/04/food-consumption-and-co2-emissions/</link>
      <pubDate>Sat, 11 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/04/food-consumption-and-co2-emissions/</guid>
      <description>This will be my first attempt at machine learning using the tidymodels package, with a dataset taken from TidyTuesday. The code used to scrape this data can be found here.
The study analyses data from the Food and Agriculture Organization of the United Nations (FAO) to determine the quantity of produce supplied for consumption of 11 food types for all countries researched. Using CO2 emissions data, the carbon footprint per capita is then calculated for each food type.</description>
    </item>
    
    <item>
      <title>Spotify Data? That&#39;s Music To My Ears!</title>
      <link>/2020/01/spotify-data-thats-music-to-my-ears/</link>
      <pubDate>Tue, 21 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/spotify-data-thats-music-to-my-ears/</guid>
      <description>This dataset was taken from the very popular TidyTuesday github repo, and this was my attempt at having a go at visualization given my love for music and this was a Spotify dataset.
In the spirit of “Perfect is the enemy of good”, this will be a short post aimed at answering just a couple of questions with EDA and visualization.
Datasets from TidyTuesday are usually cleaned (or at least there’ll be instructions/hints on what one should first start with), and I begin by importing the data and exploring it via skimr.</description>
    </item>
    
    <item>
      <title>Oil and Gas Sector 2019 (Part II)</title>
      <link>/2019/12/oil-and-gas-sector-2019-part-ii/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/12/oil-and-gas-sector-2019-part-ii/</guid>
      <description>Continuing on from Part I of this analysis, we move on Part II.
Part I: Data Importing and Wrangling (Tidying)Part II: Exploratory Data Analysis and interpretation of resultsIf you wish to replicate my findings, the raw Bloomberg data is available at my github.
Disclaimer
All data that I have used in this presentation is obtained from Bloomberg and I do not own any of it.</description>
    </item>
    
    <item>
      <title>Oil and Gas Sector 2019 (Part I)</title>
      <link>/2019/12/oil-and-gas-sector-2019-part-i/</link>
      <pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/12/oil-and-gas-sector-2019-part-i/</guid>
      <description>While preparing for an internal sector presentation, I decided to experiment with R to see if I could replicate the results generated by Bloomberg and customize it further to shed more insight. The learning curve was steep but, on hindsight, I benefitted tremendously from the following:
A great opportunity to practise all aspects of Data Science. From Importing, to Tidying, to Exploratory Data Analysis, to my first ever R Markdown document!</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>My career in the investment industry began in 2011 with a portfolio management role in a Fund of Hedge Funds and subsequently with a regional life insurer. In my current capacity, I focus on fundamental bottom-up research on corporate bonds in a regional asset management firm based in Singapore, and I’m a CFA Charterholder since 2014.
Having discovered R in 2018, I very quickly fell in love with the language, packages and community - and have been using data science to augment and refine my investment process.</description>
    </item>
    
  </channel>
</rss>