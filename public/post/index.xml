<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Desmond Choy&#39;s Blog</title>
    <link>/post/</link>
    <description>Recent content in Posts on Desmond Choy&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 29 Aug 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Predicting Coffee Quality With ML</title>
      <link>/2020/08/predicting-coffee-quality-with-ml.en-us/</link>
      <pubDate>Sat, 29 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/08/predicting-coffee-quality-with-ml.en-us/</guid>
      <description>A LASSO model, random forest model and an XGBoost model walks into a cafe&amp;hellip;</description>
    </item>
    
    <item>
      <title>Make Your Vote Count By Counting Sentences</title>
      <link>/2020/07/make-your-vote-count-by-counting-sentences.en-us/</link>
      <pubDate>Fri, 03 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/07/make-your-vote-count-by-counting-sentences.en-us/</guid>
      <description>Singapore political manifestos are categorized using NLP. The results are fed into an interactive html table that allows for convenient sorting and filtering.</description>
    </item>
    
    <item>
      <title>Scoring Visualization Goals with PCA and FIFA 20</title>
      <link>/2020/06/scoring-visualization-goals-with-pca-and-fifa-20.en-us/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/06/scoring-visualization-goals-with-pca-and-fifa-20.en-us/</guid>
      <description>I came across this interesting dataset on Kaggle related to the football simulation video game FIFA 20, with a very detailed breakdown of attributes of over 18,000 football players. It’s been a while since I’ve played a FIFA game, and an even longer time since I last worn my soccer boots, but this seemed like an excellent data set for some Exploratory Data Analysis. I also showcase ridgeline plots and network graphs with wrangled data, and take a stab at implementing and interpreting unsupervised machine learning in the form of Principal Components Analysis on our wide data set.</description>
    </item>
    
    <item>
      <title>Exploring Share Prices and Sentiment</title>
      <link>/2020/05/exploring-share-prices-and-sentiment/</link>
      <pubDate>Fri, 29 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/05/exploring-share-prices-and-sentiment/</guid>
      <description>Despite these troubling times brought upon us by Covid-19, one interesting investment theme has outperformed the market - “stay-at-home” stocks. These generally consist of companies that would benefit from the lockdown such as big retailers with delivery services, tech companies providing essential software for WFH setups, and video gaming companies that benefit from bored kids and adults. These companies have outperformed the broader indices significantly and, intuitively, sentiment for these companies should be positive, right?</description>
    </item>
    
    <item>
      <title>Hip-Hop Lyrics Be Flowing with Tidy Text Mining</title>
      <link>/2020/05/hip-hop-lyrics-be-flowin-with-tidy-text-mining/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/05/hip-hop-lyrics-be-flowin-with-tidy-text-mining/</guid>
      <description>I’ve been hit with a double dose of NLP inspiration after reading a recent Julia Silge blog post and watching a Datacamp video on Tidy Text Mining which she used to teach. Ergo, this post will set out to do two things: use sentiment analysis to explore hip-hop songs, and subsequently use the tidymodels package on the lyrics to predict which era (Old School versus Modern) the songs came from.</description>
    </item>
    
    <item>
      <title>Being Picky About Free Textbooks From Springer</title>
      <link>/2020/04/being-picky-about-free-textbooks-from-springer/</link>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/04/being-picky-about-free-textbooks-from-springer/</guid>
      <description>You might have heard that Springer Nature, an American German academic publishing company, is giving free access to more than 500 key textbooks across Springer Nature’s eBook subject collections, as their way to support lecturers, teachers and students and grant remote access to essential educational resources during this Covid-19 lockdown period. A repository of the books can be found here.
To my delight, I stumbled across the springerQuarantineBooksR package made by Renan Xavier Cortes in a blog post.</description>
    </item>
    
    <item>
      <title>Food Consumption and CO2 Emissions</title>
      <link>/2020/04/food-consumption-and-co2-emissions/</link>
      <pubDate>Sat, 11 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/04/food-consumption-and-co2-emissions/</guid>
      <description>This will be my first attempt at machine learning using the tidymodels package, with a dataset taken from TidyTuesday. The code used to scrape this data can be found here.
The study analyses data from the Food and Agriculture Organization of the United Nations (FAO) to determine the quantity of produce supplied for consumption of 11 food types for all countries researched. Using CO2 emissions data, the carbon footprint per capita is then calculated for each food type.</description>
    </item>
    
    <item>
      <title>Spotify Data? That&#39;s Music To My Ears!</title>
      <link>/2020/01/spotify-data-thats-music-to-my-ears/</link>
      <pubDate>Tue, 21 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/spotify-data-thats-music-to-my-ears/</guid>
      <description>This dataset was taken from the very popular TidyTuesday github repo, and this was my attempt at having a go at visualization given my love for music and this was a Spotify dataset.
In the spirit of “Perfect is the enemy of good”, this will be a short post aimed at answering just a couple of questions with EDA and visualization.
Datasets from TidyTuesday are usually cleaned (or at least there’ll be instructions/hints on what one should first start with), and I begin by importing the data and exploring it via skimr.</description>
    </item>
    
    <item>
      <title>Oil and Gas Sector 2019 (Part II)</title>
      <link>/2019/12/oil-and-gas-sector-2019-part-ii/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/12/oil-and-gas-sector-2019-part-ii/</guid>
      <description>Continuing on from Part I of this analysis, we move on Part II.
Part I: Data Importing and Wrangling (Tidying)Part II: Exploratory Data Analysis and interpretation of resultsIf you wish to replicate my findings, the raw Bloomberg data is available at my github.
Disclaimer
All data that I have used in this presentation is obtained from Bloomberg and I do not own any of it.</description>
    </item>
    
    <item>
      <title>Oil and Gas Sector 2019 (Part I)</title>
      <link>/2019/12/oil-and-gas-sector-2019-part-i/</link>
      <pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/12/oil-and-gas-sector-2019-part-i/</guid>
      <description>While preparing for an internal sector presentation, I decided to experiment with R to see if I could replicate the results generated by Bloomberg and customize it further to shed more insight. The learning curve was steep but, on hindsight, I benefitted tremendously from the following:
A great opportunity to practise all aspects of Data Science. From Importing, to Tidying, to Exploratory Data Analysis, to my first ever R Markdown document!</description>
    </item>
    
  </channel>
</rss>